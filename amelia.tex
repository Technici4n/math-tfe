\section{Les premières intelligences artificielles}
\subsection{Introduction et définition}

\subparagraph{}
Nous pouvons tout d’abord définir l’intelligence artificielle.
L'intelligence artificielle (IA, ou AI en anglais pour Artificial Intelligence) a pour but de mimer ou d’imiter une certaine forme d’intelligence réelle. Elle essaie de se substituer à la logique de la prise de décision d’un humain en mettant en œuvre différentes techniques.

L'intelligence artificielle est définie comme « l'ensemble de théories et de techniques mises en œuvre en vue de réaliser des machines capables de simuler l'intelligence » . 
Elle correspond donc à un ensemble de concepts et de technologies plus qu'à une discipline autonome constituée.

\subparagraph{}
La notion d’intelligence artificielle est née dans les années 50 et a été mise en avant par deux chercheurs.
Tout d’abord, le mathématicien \textbf{Alan Turing} a débuté ses recherches dans ce domaine car il se demandait si une machine pouvait penser.
Dans son article Computing Machinery and Intelligence, il cherche à savoir s’il est possible d’apporter une forme d'intelligence aux machines.
Turing a analysé le problème et a proposé une expérience connue aujourd’hui sous le nom de \textit{Test de Turing}. 
Dans ce test, un sujet interagit à l'aveugle avec un autre humain, puis avec une machine programmée pour formuler des réponses sensées. Si le sujet n'est pas capable de faire la différence, alors la machine a réussi le test et, selon l'auteur, peut véritablement être considérée comme \textit{intelligente}.
Ce test permet donc de définir si une machine est consciente.

\subparagraph{}
Ensuite, \textbf{Warren Weaver} a publié en 1949 un mémorandum. Celui-ci se base sur la traduction automatique des langues, ce qui signifie qu’une machine est capable de faire des tâches dites humaines.
Il est principalement connu comme un des pionniers de la traduction automatique.

\subparagraph{}
L’intelligence artificielle en tant que domaine de recherche a été créée lors d’une conférence qui se déroulait sur le campus de Dartmouth College pendant l'été 1956.

Les organisateurs de la conférence de Dartmouth avaient prévu que diverses questions autour de l'idée d'une machine pensante seraient abordées:
\begin{itemize}
\item Comment simuler la pensée et le langage au travers de règles formelles?
\item Comment faire penser un réseau de neurones?
\item Comment doter une machine de capacité d'apprentissage automatique?
\item Comment doter une machine de créativité?
\end{itemize}
Néanmoins, les discussions ont été assez limitées et la conférence de Darmouth n'a servi qu'à forger un embryon de communauté de recherche autour des problématiques évoquées.
\textbf{John McCarthy} a proposé le terme \textit{intelligence artificielle} pour désigner la nouvelle discipline qui a connu son âge d'or durant les 15 années suivantes.

\subparagraph{}
Si l'intelligence artificielle s’est fortement développée aux États-Unis, c'est grâce à certaines personnes de renom dont John McCarthy à Stanford, \textbf{Marvin Minsky} au MIT, \textbf{Allen Newell} et \textbf{Hebert Simon} à Carnegie Mellon ainsi que \textbf{Donald Michie} à l’université d’Edimbourg. La plupart d’entre eux ont reçu le prix Turing, c'est-à-dire le prix le plus prestigieux en matière d'informatique. 
Leur travaux sur l'intelligence artificielle seront détaillés plus loin.




\subsection{Quelques grands précurseurs de l'IA}

\subsubsection{Des scientifiques et des ingénieurs}


\subparagraph{}
\textbf{Konrad Zuse} (1910–1995) est un ingénieur allemand et l’un des fondateurs du calcul programmable. Entre  1936 et 1938, il développe Z1, le premier calculateur mécanique fonctionnant dans un moteur électrique. Pendant ce temps, il travaille sur un autre projet: il crée en 1937 le premier calculateur électro-mécanique programmable binaire à virgule flottante, le Z3. Il est opérationnel en 1941 c'est-à-dire après seulement 4 ans de travail.


\subparagraph{}
\textbf{Claude Shannon} (1916–2002) est un ingénieur électricien et un mathématicien américain. Il est l’un des pères fondateurs de la \textit{Théorie de l’information}. Il donne son nom à un schéma qui prend le nom de \textit{Schéma de Shannon}. Cet outil est utilisé en sciences humaines et en communication. En tant que  mathématicien, il utilise l’algèbre de Boole dans le but de mettre en place des circuits de commutation. Il ajoute sa pierre à l’édifice en apportant un outil théorique aux concepteurs de circuits logiques. Il se tourne ensuite vers l’informatique. Il commence à créer une machine à jongler, une souris parcourant les labyrinthes, une machine qui résout le Rubik's cube et une autre machine permettant de jouer aux échecs.


\subparagraph{}
\textbf{Allen Newell} (1902-1992) a été chercheur en informatique ainsi qu'en psychologie cognitive au sein de deux organismes : RAND Corporation et Carnegie Mellon’s School of Computer Science aux Etats Unis. Il participe à l'élaboration de différents programmes : \textit{Information Processing Language} en 1956 et à deux programmes en Intelligence Artificielle \textit{The Logic Theory Machine} (1956) et le \textit{General Problem Solver} (1957). Pour ce dernier programme, il travaille en collaboration avec Herbert Simon.


\subparagraph{}
\textbf{John Mc Marthy} (1927-2011) est l'un des pionniers de l'Intelligence Artificielle avec Marvin Minsky. Il met l'accent sur la logique symbolique. En 1948, John McCarthy obtient un Bachelor of Science en mathématiques au California Institute of Technology, puis un doctorat à Princeton en 1951. Sa thèse porte sur un certain type d'équations aux dérivées partielles, mais son passage à Princeton lui fait rencontrer Minsky avec qui il se découvre une passion commune pour l'idée de machine pensante. A l'âge de 28 ans, il élabore un algorithme qui jouera un rôle majeur dans la programmation en Intelligence Arficielle. Cette algorithme est utilisé dans la plupart des programmes d'échecs. En 1958, il met au point le langage List Processing, LISP. Il crée à l'Université Standord le laboratoire de l'Intelligence Artificielle. 




\subsubsection{Un économiste}

\textbf{Herbert Simon} (1916-2001) était avant tout un économiste et sociologue américain. Il a utilisé pour la première fois les ordinateurs et en a conclu que l'ordinateur avait deux rôles, à savoir la reproduction de la pensée humaine et la systématisation de celle-ci. Sa rencontre avec Allen Newell a été primordiale car il s'est penché sur les activités intellectuelles humaines et a découvert qu'elles pouvaient être automatisées. Ils ont conçu le \textit{General Program Solver} en 1957 et ont développé l'intelligence artificielle de différentes manières. 



\subsubsection{Des influences littéraires}

\subparagraph{}
\textbf{Isaac Asimov} (1920-1992) est un écrivain américain. Il a écrit des œuvres de science-fiction ainsi que des livres de vulguratisation scientifique. Il a aussi écrit une série d'histoires (série des Robots) sur les rapports conflictuels entre l'homme et la machine ainsi que sur le rôle des robots. 

\subparagraph{}
\textbf{Hubert Dreyfus} (1929-2017) est un professeur américain de philosophie à l'université de Californie. Il s'intéresse à différents sujets comme la phénoménologie, l'existentialisme, la philosophie de la psychologie, la littérature et bien sûr l'intelligence artificelle. Il critique notamment fortement Allen Newel et Herbert Simon dans son livre \textit{Alchemy and Artificiel Intelligence}.

 



\subsection{Apparition des premiers ordinateurs}
\subparagraph{}
Les années 1940 et 1950 voient l'apparition des premiers véritables ordinateurs.
Ils sont Turing complets et électroniques, donc (relativement) rapides. Les entrées et sorties se font par cartes perforées et impression papier. La programmation de telles machines est compliquée et très longue. Il n'existe que très peu d'ordinateurs, uniquement dans quelques universités ou grandes entreprises. Ces machines couteuses servent surtout à faire des calculs massifs(statistiques pour l'état, calculs
scientifiques pour la recherche nucléaire, calculs balistiques pour l'armée, etc.). Par exemple, l'\textit{UNIVAC I} (Universel Automatic Computer) est installé en 1951 au bureau du recensement américain.
\subparagraph{}
Notons bien que l'informatique n'existe pas encore. Les spécialistes des ordinateurs sont en effet essentiellement des mathématiciens ou des électroniciens. Les langages de programmation au sens moderne du terme n'existent pas encore : le premier langage évolué, \textit{FORTRAN} (FORmula TRANslator) ne verra le jour qu'en 1954. 
L'apparition des ordinateurs semble néanmoins rendre possible le rêve de l'IA. Les deux approches de l'IA vont émerger dans les années 1940 à savoir le connexionnisme et le cognitivisme.
\subparagraph{}
Le \textbf{connexionnisme} modélise les phénomènes mentaux ou comportementaux comme des processus émergents de réseaux d'unités simples interconnectées. Le plus souvent les connexionnistes modélisent ces phénomènes à l'aide de réseaux de neurones.
\subparagraph{}
Quant au \textbf{cognitivisme}, il est le courant de recherche scientifique endossant l'hypothèse selon laquelle la pensée est analogue à un processus de traitement de l'information. Il considère que la pensée peut être décrite à un niveau abstrait comme manipulation de symboles, indépendamment du support matériel de cette manipulation (cerveau, machine électronique, etc.).
Elle est définie en lien avec l'intelligence artificielle comme une manipulation de symboles ou de représentations symboliques effectuée selon un ensemble de règles. Cette approche établit un lien entre la pensée et le langage (système de symboles).

\subparagraph{}
Le 20ème siècle voit de fait apparaitre plusieurs théories comme la cybernétique et le cognitivisme pour modeliser l'esprit, le cerveau et le mode de fonctionnement de la pensée. De surcroît, dans le contexte de la guerre froide, la traduction automatique du russe en anglais ou de l'anglais au russe est cruciale.En effet, en 1954, un premier programme, écrit àl'université de Georgetown permet de traduire plusieurs dizaines de phrases simples. Le programme utilise 250 mots et seulement 6 règles de grammaire et tourne sur un IBM 701.

\subparagraph{}
Des crédits sont rapidement alloués aux recherches sur la traduction automatique (aussi bien aux USA qu'en URSS). Les premiers travaux visent la traduction directe, presque mot à mot, à l'aide de dictionnaires bilingues et de règles simples. Les problèmes de polysémie (amateur, blanc) ou d'homonymie (mousse, avocat, ...) apparaissent cependant très rapidement.                      


\subsubsection{Les travaux de Simon et Newell}

\subparagraph{}
Allen Newell, après un Bachelor of Science en physique à Stanford, rejoint Princeton en 1949 pour mener une thèse en mathématiques. Durant ses études, il a été fortement influencé par le mathématicien hongrois Georges Polya (1887-1985), qui avait introduit la notion d'heuristique pour la résolution de problèmes. Une heuristique (du grec \textit{Eurisko, Je trouve}) est une méthode empirique de résolution de problèmes, dont la validité ou l'efficacité n'est pas prouvée. Par exemple, protéger la reine aux échecs, choisir la caisse où la file est la plus courte, ...
Trouvant finalement les mathématiques trop abstraites, Newell accepte en 1950 un poste à la RAND Corporation de Santa Monica, pour mener des travaux plus concrets, sur l'aéronautique de défense notamment.

\subparagraph{}
Simon est également consultant à la RAND (Research ANd Development). La RAND, créée pour étudier la mise au point d'un satellite artificiel, va peu à peu étendre ses travaux à l'informatique, l'économie et la géopolitique. Les idées de Simon et de Newell convergent : La rationalité limitée de Simon implique que la prise de décisions repose sur des procédures permettant de palier aux manques d'information en tenant compte du contexte. Pour Newell, ces procédures sont des heuristiques.

\subparagraph{}
Simon et Newell considèrent que la condition nécessaire et suffisante pour qu'une machine puisse faire preuve d'intelligence est qu'elle soit un système physique de symboles.
Néanmoins, ils mettent au coeur de leurs travaux la notion d'heuristique : être intelligent, c'est aussi être capable de construire des heuristiques, de les tester, de les faire évoluer. Aidés par un programmeur de la RAND, Cliff Shaw, ils développent Logic Theorist en 1956, un programme de démonstration automatique de théorèmes (voir l'article The logic theory machine: A Complex Information Processing System, 1956). Pour faciliter la programmation du Logic Theorist, Newel, Simon et Shaw développent le langage IPL (Information Processing Language) en 1956.
Logic Theorist est considéré comme le premier programme informatique relevant du domaine de l'IA.

Newell et Simon y démontrent une série de théorèmes et envoient un article avec leur nouvelle démonstration au Journal of Symbolic Logic. L'article est cependant refusé au motif que ce théorème est déjà démontré depuis longtemps. Simon écrira néanmoins dans son autobiographie : « nous avons inventé un programme informatique capable de penser de façon non-numérique et, de ce fait, avons résolu le vénérable problème de l'âme et du corps, en expliquant comment un système composé de matière pouvait exhiber les propriétés de l'esprit » (Models of My Life, H.
Simon, 1991).

\subparagraph{}
Notons que les travaux de Newell et Simon illustrent également les apports croisés entre l'informatique et l'intelligence artificielle. On a d'une part le développement de l'informatique rendu possible par des expériences en IA, et d'autre part les problèmes posés par les expériences en IA qui conduisent à produire des outils servant au développement de l'informatique.

\subsection{Aujourd'hui}

\subsubsection{Le Japon et l'IA}

\subparagraph{}
Bénéficiant des techniques de l'intelligence artificielle, la transmission des savoirs vit au début des années 90 une révolution. Les concepts sont bouleversés. Ils s'enrichissent de l'apport du couple IA-Robotique qui crée ses propres spécificités.

Si les robots font déjà partie intégrante du paysage industriel japonais, où ils servent à réaliser des tâches dangereuses ou nécessitant une haute précision de manière automatique, une évolution majeure du marché se dessine avec l’émergence de la robotique de service et, dans une moindre mesure, de la robotique de loisir.

Les Japonais sont depuis très longtemps les champions de la robotique et on ne compte plus leurs inventions. Les recherches actuelles concernent tout particulièrement les robots \textit{humanoïdes}, qui tentent d’immiter les humains et leurs capacités.

\subparagraph{}
Par exemple les robots humanoïdes présentent plus de difficultés de développement, puisqu’il s’agit d’immiter des facultés humaines, ce qui n’est pas simple. Le Japon rencontre un problème très particulier avec une natalité très faible et donc un vieillissement très important de la population qui nécessite de plus en plus d’aide. C’est pour cette raison que Honda continue de travailler sur ASIMO, le robot humanoïde qui devrait aider les personnes âgées à rester à leur domicile, en les assistant dans de nombreuses tâches qu’ils ne peuvent assumer seuls. Par ailleurs, des chercheurs de l’université de Tohoku, associés à des chercheurs français, consacrent leurs travaux à la résolution d’un problème très important : permettre à un robot humanoïde, HRP-2, de se déplacer sur des surfaces irrégulières. En effet, ce type de robot ne peut se déplacer que sur une surface dure et stable, ce qui limite fortement son champ de manœuvre. La résolution de ce problème représenterait une avancée considérable en robotique et donc également en intelligence artificielle.


\subsubsection{L'IA dans tous les domaines}
\subparagraph{}
D’année en année, l'IA a été implantée dans de plus en plus de domaines d'application et le développement de celle-ci est au centre de beaucoup de recherches actuelles. 
Le développement des technologies informatiques et des techniques algorithmiques ont eu une telle croissance ces dernières années que les machines dépassent l’homme dans plusieurs domaine comme le jeu d’échecs ou encore le jeu de go.

Toutefois, les sujets concernés par l’IA ont varié au cours du temps. Par exemple, dans les années 1950, la recherche d'un itinéraire était considéré comme un problème d'intelligence artificielle, alors qu’aujourd’hui, il existe différentes applications qui sur base d’algorithmes résolvent ces questions de recherche d'itinéraires et il ne s’agit plus d’intelligence artificielle.

\subparagraph{}
Aujourd’hui toutes les grandes entreprises dans le monde de l’informatique (Google, Microsoft, Apple, IBM ou Facebook) portent une attention toute particulière aux problématiques de l'intelligence artificielle en tentant de l'appliquer à différents domaines précis. 
Chacun met ainsi en place des réseaux de neurones artificiels constitués de serveurs afin de traiter de lourds calculs au sein de gigantesques bases de données.

\subparagraph{}
L’intelligence artificielle est aussi de plus en plus utilisée pour être au service des humains. Par exemple, la vision artificielle comme nous l’expliquerons dans ce travail, permet à la machine de déterminer précisément le contenu d'une image comme des pièces de monnaies pour ensuite la classer automatiquement selon l'objet, la couleur ou le visage repéré. 

La reconnaissance vocale a également le vent en poupe avec des assistants virtuels capables de transcrire les propos formulés en langage naturel puis de traiter les requêtes soit en répondant directement via une synthèse vocale, soit avec une traduction instantanée ou encore en effectuant une requête relative à la commande. Apple était en la matière un des précurseurs avec son application Siri.

\subparagraph{}
Nous pouvons donc affirmer que l’IA qui était au départ très restreinte a un potentiel infini. 
De jour en jour, les recherches progressent et les résultats de ce que l’intelligence artificielle est capable de réaliser croissent de manière exponentielle.




